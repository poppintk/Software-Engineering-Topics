Load parameter: A parameter is used to describe the system load.
different systems required different load parameter. it can be  request/sec send to web server
it can be read write ratio that database, and daily active user in chating system.
it can be cache hit rate for the cache system.


Tweeter for example,
1) publish tweet - users can send tweet to server (avg 4.6k request/sec, peak 12k request/sec)

2) get timeline - fetch all tweet from following users (300k request/sec)

the main issue on tweeter is on fan-out issue, like each user can follow many other users and each user can be followed by other uses

Tweeter use two approach
1) pull model
  publish tweet - when users publish tweet, all tweets are saved on their tweet table.
  
  get timeline - current user actively calling get timeline api to get all tweet from following users(slow requires lots of join, if data volumn is large)
  
  Cons: too slow
  Pros: less pressure on the writing compare to push model
  
2) push model
  publish tweet - when users publish tweet, all tweets are saved on their tweet and all followed user's tweet table.
  Since write to db is slow so this required MQ to write Asyc to the db.
  
  How to improve write to db? (Naive approach is use db, better way is use cache)  
  
  for every user, Tweeter maintained timeline cache. so when a user publish tweet,
  all tweets are firstly send to MQ then fan out deliver tweets to all the cache.
  
  get timeline - current user actively calling get timeline api to get all tweet from users(fetch data from the cache)
  
  
  Tweeter use approach 1) earilier then switch to 2) as data size grow larger.
  2) is better than 1). but 2) still not perfect.
  
  Star effect issue, if a super star user publish a tweet, it will consume huge computation power to do.
  in such a case, it is better to separe normal user and super star user.
  
  normal user use 2) super start user use 1)
  
  
  How to describe system performance?
  Batch system -> throughput
  Online system -> response time (latency + proccess time)
  
  percentiles
    -> p95(95%)
    -> p99(99%)
    -> p999(99.9%)
    
  
  
  

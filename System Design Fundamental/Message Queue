Message Queue:
use case:
   1) asyc task
   2) decoupling between services
   3) controll the trafic on peak time, in order to protect downstream services
concepts:
   1) message broker
   2) destination
JMS(Java Message Service) Java base Message queue
- base on JVM message broker standard. ActiveMQ, HornetMQ are JMS implementation

AMQP(advanced Message Queuing Protocol)
- Advanced message queue protocol, JMS compatible
- RabbitMQ is AMQP implementation

RabbitMQ:
   Message:
      message body: not public accessible
      message head: routing-key, priority, delivery-mode(durable)
   Publisher:
      Message producer, send message to exchange of Message queue application
   Exchange:
      use for receiving producer's message and routing those message to correct queue
      4 types: direct(default), fanout, topic, and headers
   
   Queue:
      use for keeping message until messages are sent to consumer. A message can be sent to many queues.
      messages are waiting for consumer to take them away
  
   Binding:
      binding exchange and queue (can be many to many)
      
   Consumer
   
   Virtual host:
      represent whole bunch of exchanges, queue and binding with separant excution environment
   
   Broker:
      many of virtual host together
   
   Connection:
      in Rabbit Queue only on TCP connection is created
   
   Channel:
      use multiplexing bidirectional channel in the TCP connection. AMQP command is sent through channel, 
      Whatever publish, subscribe and receving messages all sent through channel.
      
      
      
      
## Reliable Message Queue
   in order to guarrantee message won't lose, we can use transaction, but throughput will be decreased by a factor of 250
   therefore we use confirm callback instead
   
   NOTE: reliable => need table to store message in the database with status(NOT SEND, SEND, QUEUED, CONSUMED) like a log
   then use callback to keep tracking status. if some message not deliver successful then required scheduler job to re-run.
   
   Producer   -------->   | Broker Exchange ----> Queue | ------>  Consumer

Producer ---> Broker (confirmCallback, triggered as long as broker receives, if cluster only triggers when all broker receive)
Exchange ---> Queue (returnCallback, triggered when message FAIL to deliver to the queue)
Queue ---> Consumer ack
   1) by default auto-ack, as long as consumer consumed then message will be removed from MQ
      issue:
         if more messages delievered and only one message processed, at this moment machine down => message lose
         Solution: consumer manually ack. as long as message not call ack(), the message will be on unacked status. if consumer service down then message will be re-push to MQ
   2) How to ack:
      channel.basicAck(deliveryTag, false); //ack, should be called bussiness logic process successfully
      channel.basicNack(deliveryTag, false, true);// not ack

General issues on MQ?
      1) Message lost: 
        a) message sent, but due to network lost
          - try catch and retry
          - logging (new table in database for logging)
          - schedule job resend unsuccessful message
         b) Message arrive Broker, Broker need to write into disk, but before writting to disk, service down
          - publisher also need callback, after confirm successful then change database message status
         c) Auto-ACK, The consumer received message, but not yet mark ACK, service down
          - Must mannually ACK and after confirming consumed successfully then remove message. if failue then noACK and re-push back to queue
      2) Message duplicated
        a) The consumer consume message successfully and transaction commited. the machine down right on the ack so that ack not go through. Broker message re-send message
        from unack status to ready status and send to other consumers
        b) message consumed failed but due to retry and double sending message
        soluction: Idempodence
      3) Message Pressure on consumer/subscribe server side
        a) consumer unavaible 
        b) consumer consuming speed less than producer produce
        Soluction:
          - more consumers
          - create message consuming service, firstly batch saving message into database then offline processing
      4) Consumer Server might crash if poll too many message to process(beyond its machine limitation)
         Solution: config the prefetch size base on machine ablility
          
 How to scale?
   - to scale the throughput for RabbitMQ can use RabbitMq sharding plugin or use nginx to balance load ( scale for throughput)
   - fanout (scale for the consumers)

 Resilience?
   master slave, sync data between master and slave
   
   
   
##################################################################################################
Kafka
   Broker: one kafka server is one broker
   Partition: a partition is a sequence queue, each message in the queue has a sequential id(offset)
   Topic: group of partition
   Offset: the sequential id in the partition
   Consumer Group: group of consumers, consumers in a same group can only fetch data from a topic exactly once (there is no overlaping in fetched data).But multiple groups can fetch to same topic at the same time.
   
   Log base Message Broker, detail see the ddia ch11 
   
   Kafka require third party tool for the service discovery, recommmended Zookeeper
   
   
   Why Kafka allows high throughput?
      - zero copy
      - sequential write
      - pre-fetch
      - post-write (in buffer, then aggregate to disk)
      - segment logs
      - batch process
      - compression 
  
  Where is offset stored in Kafka?
      - eariler version on Zookeeper
      - later version on Kafka cluster(zookeeper topic(_consumer_offset))
      - customized (Redis or DB)
      
  How consumers consume data from the Kafka?
      - Poll (Consumers and Broker system has different throughput, use poll let consumer decide when consumer is ready to take next data)
      
  How Kafka guarantee data won't lose or prevent dulicated consume?
      Producer:
         - Producer sync sending data and ACK = -1(all)
      Broker Cluster:
         - Replicate sync between leader and followers
      Consumer:
         - when Kafka rebalance, data might lose. Solutions?
         - Maintain customized offset(use Lower level API)
         
  Where is Kafka medadata stored?
      - Zookeeper (/controller, /cluster, /consumer /broker)
  
  Why use Kafka?
      - high throughput, sequential order and consumers easy
      
      
  
  
   


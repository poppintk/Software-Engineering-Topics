Message Queue:
use case:
   1) asyc task
   2) decoupling between services
   3) controll the trafic on peak time, in order to protect downstream services
concepts:
   1) message broker
   2) destination
JMS(Java Message Service) Java base Message queue
- base on JVM message broker standard. ActiveMQ, HornetMQ are JMS implementation

AMQP(advanced Message Queuing Protocol)
- Advanced message queue protocol, JMS compatible
- RabbitMQ is AMQP implementation

RabbitMQ:
   Message:
      message body: not public accessible
      message head: routing-key, priority, delivery-mode(durable)
   Publisher:
      Message producer, send message to exchange of Message queue application
   Exchange:
      use for receiving producer's message and routing those message to correct queue
      4 types: direct(default), fanout, topic, and headers
   
   Queue:
      use for keeping message until messages are sent to consumer. A message can be sent to many queues.
      messages are waiting for consumer to take them away
  
   Binding:
      binding exchange and queue (can be many to many)
      
   Consumer
   
   Virtual host:
      represent whole bunch of exchanges, queue and binding with separant excution environment
   
   Broker:
      many of virtual host together
   
   Connection:
      in Rabbit Queue only on TCP connection is created
   
   Channel:
      use multiplexing bidirectional channel in the TCP connection. AMQP command is sent through channel, 
      Whatever publish, subscribe and receving messages all sent through channel.




Distributed Cache:

Use case:
- System requires low real-time and allow eventually consistent
- Read more and write less

Common cache system issues:
   Cache read issue:
      1) Cache Avalanche
         All cache keys TTL expires at the same time, So all the requests go to DB => DB down
         Solution: Adding randomly TTL to the cache keys

      2) Cache Penetration
        User requests the key does not exist on the DB, so the key must not in the cache as well, So all the requests go to DB => DB down
        Solution: 1)Bloom Filter 2) Allowing null as value to the cache key and also setup TTL.     

      3) Hotspot Invalid
        There are hot data that User keep requesting to the cache(large QPS), right at the point of time TTL get expired, Soall requests go to DB => DB down 
        Solution: Use locks, if distributed then use distributed locks
  
  
Cache update issues(write):
   Double write: when data is updated, write to update both DB and cache. 
   Lazy Loading: when data is updated, firstly update DB data then delete cache.
   under high concurrency senerio both cases will cause data inconsistency. adding TTL to make it eventually consistent.
   
   - what if system requires strong consistency? (depends on senerio)
      - Distributed locking service will reduce efficiency(network call)
      - use Canal for MySQL
      - Write more read less senerio, use read from DB directly
      
      conclusion: 
         if system write more and read less requires strong consistency => no cache 
         if system read more and write less requires storng consistency => use distributed lock or Canal for MYSQL
      
   Best practice: lazy loading: database.set(key,user); cache.delete(key)
   
   
   
  
Distributed Lock (Redison - Redis based distributed lock framework)
   - Reentrance Lock
   - ReadWrite Lock
   - Semaphore
   - CountDownLatch
   
   
Spring cache
   cons:
      cache read:
         - Cache Penetration: cache-null-value = true
         - Hotspot Invalid: local locking, by default no locking, require set sync = true
         - Cache Avalanche: use only TTL 
      cache write(cache update):
         - use only TTL for eventually consistent
   
   
Distributed Session issue:
   1) cannot share on different domain
   2) Load balancing to arbitrary machine and that machine not guarrantee have the previous stored session
   
   
Oauth2 flow for web server:
   1) client browser click on the Oauth2 login icon, Request to third party for the login with redirect URL(for web server)
   2) Users input their third party login
   3) After authenticate third party authorization server redirect back to the URL(web server) with access token(code)
   4) The web server now can call POST request ask for public protected user information. Note the POST body requires access token(code) just return
   CLIENT_ID, CLIENT_KEY those can be access from the third party
   5) public protected information is returned
   
   
   
   
 Distributed session issues:
   1) different domains, session cannot be shared among different domains
      but session can be share among its sub-domain(zi yun ming)
   
   2) in distributed system, load balancer might routing to different machine, and current machine might not have session.
      solution: 
         1) session replicate syncronously between web servers.
            pros:
               web-server(tomcat) supports it, need to config
            cons:
               - session replecate synconously need network transmission as result lower the cluster performance
               - session cannot horizontally scale if session size too big
               - in distributed system, this approach not work well
          2) save session on client side
             pros:
               web server now does not need to sotre session inforamtion. uses save their session information on cookie.
             
             cons:
               - each every session need to be stored data insize cookie, cookie size limitation is 4KB, cannot store big inforamtion
               - cookie is unsecured and likely be hacked
           
           3) hash consistent so that every request will hash to same web server
               pros: 
                  - only required nginx configration, no code required
                  - all web server horizontally scale
               cons:
                  - when adding/remove new webservers rehashing required, and some users might hash to wrong session
                  
            4) Storage: Database/Redis
               Pros:
                  - safe
                  - allow horizontally scale (sharding by key)
                  - web server restart wont lost data
                  
               cons:
                  - required additional network access.
                  - Redis get data still slower than get data from memory directly
      
      
      SMS API protection:
         Why? public API need be called too often
         - one workable solution is use Redis to save key-value pair key is the phone number and the value is SMS code + current system time
         - Rate limiter can also work
    
          

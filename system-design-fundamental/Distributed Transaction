
## Local Transaction

Data inconsistant issue with local transactional rollback on Exception

Assume we have three service : A,B and C
their calling chain is A -> B -> C
example :
in A service 
processA() {
  doSomeWork();
  B();
  C();
}

1) if call B() RPC fail we can throw Exception to trigger rollback,
but what if B() just network delay? in that case, if B has change someting in the DB and we rollback changes on A.
This will be issue. Because we expect all should rollback.

2) C() failed, in such case B() will never rollback

network delay issue + distributed machine => Distributed Transaction

Local Transaction
ACID
1) Atomicity
2) Consistency
A:1000 B: 1000 => A transfer 100 to B => A:900 B:1000. Violates consistency because before transfer,A + B = 2000 and after transfer A + B = 1900
3) Isolation
4) Durability: As long as transaction commit, data should be on the disk

On local transaction, mutlple operations share the same connection to database, so any exception occurs we can rollback all operations on database


Isolation level (Ranking lowest to highest):
  1) Read Uncommited
  2) Read Commited
  3) Repeatable Read(MySQL default)
  4) Serializable
  
Spring local transaction propagation -> determine whether or not inside the methods call should share a transaction or separate transaction

Spring @transactional drawback:
  1) Under same class transactional methods call each, transactional only work for transactional method at top level, all transaction setting 
  like propagation and timeout setting will not take affect for lower level transaction mothods, because @transactional use proxy pattern.
  How to resolve? Use proxy object to call tranction method. use <spring-boot-starter-apo> see #284 for detail
  
  
  ## Distributed Transaction
  
  CAP theorem
  
  C - Consistency
    All system nodes at the same time should keep same value
  A - Availability
    Service node(s) goes down, system still operate as usual
  P - Partition tolerance
    Separate system into different region like one data center in China and one in US
    The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes,
    continue to provide consistency and availability
  
  
  in distribute system, we gurrantee AP and CP because P is required for most of the distributed system
  It's impossible to maintained CA distributed system, like everything in a single machine.(Not a distributed system)
  
  Raft algorithm gurrantee CP
  http://thesecretlivesofdata.com/raft/
  
  # Issue CP
  For most large distributed system(Ecommerce like Amazon) in industry, required AP and sacrifice Consistency. Because availibity is more important than consistency
  
  # BASE theorem
  Extension to the CAP. The idea is for the most of distributed system, 
  we cannot gurrantee the strong consistency, but can gurrantee the weak consistency and eventually consistency.
  
    1) Basically Available (BA)
      Allowing some of the system lose availability (like response time increase). Note system is not absolutely unvailalbe
    
    2) Soft State(S)
      true - have data
      false - not exist data
      middle state - data replication
      The system existing middle state and this middle state will not impact on system availability. Time delay on sync replication. MySQL async replication is also a example 
    
    3) Eventual Consistency(E)
      Eventually consistency is special case of weak consistency
      
  
  
  # Strong consistency, weak consistency and strong consistency
  
  1ï¼‰Strong consistency
    After inserting/updating data, following reading must have the most recent updated data 
  2) Weak consistency
    After inserting/updating data, following reading allow to have time delay to get the most recent updated data OR the following reading cannot get the most recent updated data
  3) Eventually consistency
    After inserting/updating data, following reading allow to have time delay to get the most recent updated data.
    
    
  # Distributed transaction 
  1) 2PC(2 phase commit) refer #287 
    - Seata implementation
    - Not great for high concurrent system, low performance. The best use case backlog admin system.
    - 3PC 
  2) TCC (Try Confirm Cancel)
    - Hard transaction: follow ACID theorem, Strong consistency
    - Soft transaction: follow BASE theorem, Weak consistency
    - need developer to develope three logic Try, Confirm and Cancel
    - Not great for high concurrent system, low performance.
    
  3) Soft Transaction - use MQ try best to send, if failed retry (Allow high concurrent)
  4) Soft Transaction - reliable MQ + Eventually consistency(Async confirmation)  (Allow high concurrent)
  - good for high conccurrent scenerio
  - issue on using scheduler tasks: 
      1) Assuming 30mins per trigger. then worse case could be 59 mins and best case is 30 mins.
      2) Increase DB pressure
    Solution: Dead letter exhange MQ
    - use two MQ, one MQ for 5 mintues delay queue and another MQ for receiving delay message. The delay queue will set TTL with 5mins delay.
    after 5mins,  the message will route to the second MQ and the second MQ will be consume by consumer. The consumer will do the rollback logic. (Eventually consistency)
    
   - How to ensure reliable MQ?
    issues:
      1) Message lost: 
        a) message sent, but due to network lost
          - try catch and retry
          - logging (new table in database for logging)
          - schedule job resend unsuccessful message
         b) Message arrive Broker, Broker need to write into disk, but before writting to disk, service down
          - publisher also need callback, after confirm successful then change database message status
         c) Auto-ACK, The consumer received message, but not yet mark ACK, service down
          - Must mannually ACK and after confirming consumed successfully then remove message. if failue then noACK and re-push back to queue
      2) Message duplicated
        a) The consumer consumer message successfully and transaction commited. the machine down right on the ack so that ack not go through. Broker message re-send message
        from unack status to ready status and send to other consumers
        b) message consume failed but due to retry and double sending message
        soluction: Idempodence
      3) Message backlog
        a) consumer unavaible 
        b) consumer consuming speed less than producer produce
        Soluction:
          - more consumers
          - create message consuming service, firstly batch saving message into database then offline processing
 
